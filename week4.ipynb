{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9QMqebZ23l2t9ErygPD6m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramizcihe/week4-cihe240058/blob/main/week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"1. Dataset Preparation\n",
        "Import the cyberbullying dataset (e.g., from Kaggle or other public sources).\n",
        "Explore the dataset structure, label distribution, and check for class imbalance.\n",
        "Clean the dataset by removing:\n",
        "Missing or null values\n",
        "Duplicate entries\n",
        "Irrelevant content (e.g., ads, unrelated text)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "GhPTaHxibrNt",
        "outputId": "358cf7a2-6e0a-4ee4-fa68-de0a29c6735f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. Dataset Preparation\\nImport the cyberbullying dataset (e.g., from Kaggle or other public sources).\\nExplore the dataset structure, label distribution, and check for class imbalance.\\nClean the dataset by removing:\\nMissing or null values\\nDuplicate entries\\nIrrelevant content (e.g., ads, unrelated text)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aK45GBciZSNw",
        "outputId": "9a67d234-1fc7-4877-be04-7d2784756a73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          tweet_text cyberbullying_type\n",
              "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
              "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
              "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
              "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
              "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfc01882-898c-4fa8-a334-c500b2cb2f04\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>cyberbullying_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In other words #katandandre, your food was cra...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfc01882-898c-4fa8-a334-c500b2cb2f04')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfc01882-898c-4fa8-a334-c500b2cb2f04 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfc01882-898c-4fa8-a334-c500b2cb2f04');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2db9c230-d0ae-4a33-809e-8e7b8263be92\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2db9c230-d0ae-4a33-809e-8e7b8263be92')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2db9c230-d0ae-4a33-809e-8e7b8263be92 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 47692,\n  \"fields\": [\n    {\n      \"column\": \"tweet_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 46017,\n        \"samples\": [\n          \"@AndyEaston85 Love how we are teaching the Bullshitters a lesson in football. Miss Bully and his message board posts.\",\n          \"GYUK | Anti-feminist YouTuber doubles down on vile Jess Phillips rape joke while leaping to the defence ...: In a video uploaded Thursday (April 23), former UKIP candidate Benjamin jumped to the defence of retired gay porn actor turned men's rights\\u2026 http://dlvr.it/RVRS8h\",\n          \"@Truth_Haqq Islam declared war on all mankind 1400 years ago. Now we return the favor. http://t.co/av4B4yCQzY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cyberbullying_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"not_cyberbullying\",\n          \"gender\",\n          \"ethnicity\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset (replace with your dataset path or URL)\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ramizcihe/week4-cihe240058/refs/heads/main/cyberbullying_tweets.csv\")\n",
        "\n",
        "# Show first 5 rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qscnx5_aTC4",
        "outputId": "aa3acf45-8a7d-4cf3-95d1-b2051093db48"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['tweet_text', 'cyberbullying_type'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['cyberbullying_type'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "mIo1qNkxagq7",
        "outputId": "5f091f29-eecd-4390-fae7-17f964db0250"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cyberbullying_type\n",
              "religion               7998\n",
              "age                    7992\n",
              "gender                 7973\n",
              "ethnicity              7961\n",
              "not_cyberbullying      7945\n",
              "other_cyberbullying    7823\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cyberbullying_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>religion</th>\n",
              "      <td>7998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>7992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>7973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ethnicity</th>\n",
              "      <td>7961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>not_cyberbullying</th>\n",
              "      <td>7945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>other_cyberbullying</th>\n",
              "      <td>7823</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['tweet_text']                # features\n",
        "y = df['cyberbullying_type']        # target"
      ],
      "metadata": {
        "id": "rKepe8DaajTk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "RogyW8tnamct"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with null values\n",
        "df = df.dropna()\n",
        "\n",
        "print(\"After removing nulls:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRaPgWYqa3XE",
        "outputId": "f2880e07-bdcd-4057-f5dd-865e7b4894c2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After removing nulls: (47692, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(\"After removing duplicates:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MIlN0wFa8Ve",
        "outputId": "57cd36dd-2064-4124-95c6-495df25d1097"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After removing duplicates: (47656, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "SVJ_wLjja_mp",
        "outputId": "9b5ac91a-4509-4ccf-d9fd-a68d3c534389"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        In other words #katandandre, your food was cra...\n",
              "1        Why is #aussietv so white? #MKR #theblock #ImA...\n",
              "2        @XochitlSuckkks a classy whore? Or more red ve...\n",
              "3        @Jason_Gio meh. :P  thanks for the heads up, b...\n",
              "4        @RudhoeEnglish This is an ISIS account pretend...\n",
              "                               ...                        \n",
              "47687    Black ppl aren't expected to do anything, depe...\n",
              "47688    Turner did not withhold his disappointment. Tu...\n",
              "47689    I swear to God. This dumb nigger bitch. I have...\n",
              "47690    Yea fuck you RT @therealexel: IF YOURE A NIGGE...\n",
              "47691    Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...\n",
              "Name: tweet_text, Length: 47656, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In other words #katandandre, your food was cra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47687</th>\n",
              "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47688</th>\n",
              "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47689</th>\n",
              "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47690</th>\n",
              "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47691</th>\n",
              "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47656 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct for your dataset\n",
        "X = df['tweet_text']\n",
        "y = df['cyberbullying_type']"
      ],
      "metadata": {
        "id": "QnrYbzixbP5X"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "2. Text Preprocessing\n",
        "Lowercase all text.\n",
        "Remove stopwords, punctuation, numbers, and special characters.\n",
        "Tokenize the text into words.\n",
        "Apply stemming or lemmatization.\n",
        "Optionally remove very rare or very frequent words to reduce noise\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "r4-QibBlaC-Q",
        "outputId": "79ad5458-9dc8-421a-d672-48ab47c51014"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n2. Text Preprocessing\\nLowercase all text.\\nRemove stopwords, punctuation, numbers, and special characters.\\nTokenize the text into words.\\nApply stemming or lemmatization.\\nOptionally remove very rare or very frequent words to reduce noise\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "['tweet_text', 'cyberbullying_type']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhL5HepqcC9n",
        "outputId": "8824ae14-8ab6-41a7-a392-2c5a089e09a6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tweet_text', 'cyberbullying_type']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet_text']          # ✅ correct features\n",
        "df['cyberbullying_type']  # ✅ correct labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "VFHRXG5Ncd15",
        "outputId": "75b5ae7f-bca2-4adc-ff36-578d8ddc3a1b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        not_cyberbullying\n",
              "1        not_cyberbullying\n",
              "2        not_cyberbullying\n",
              "3        not_cyberbullying\n",
              "4        not_cyberbullying\n",
              "               ...        \n",
              "47687            ethnicity\n",
              "47688            ethnicity\n",
              "47689            ethnicity\n",
              "47690            ethnicity\n",
              "47691            ethnicity\n",
              "Name: cyberbullying_type, Length: 47656, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cyberbullying_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47687</th>\n",
              "      <td>ethnicity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47688</th>\n",
              "      <td>ethnicity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47689</th>\n",
              "      <td>ethnicity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47690</th>\n",
              "      <td>ethnicity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47691</th>\n",
              "      <td>ethnicity</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47656 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # new requirement in latest NLTK\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDWIUM6IdnBV",
        "outputId": "b984c446-38c8-486b-fd71-6680b638a1fe"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "\n",
        "# Download NLTK resources (only first time)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# 1. Lowercase\n",
        "df['clean_text'] = df['tweet_text'].str.lower()\n",
        "\n",
        "# 2. Remove punctuation, numbers, special characters\n",
        "df['clean_text'] = df['clean_text'].apply(lambda x: re.sub(r'[^a-z\\s]', '', x))\n",
        "\n",
        "# 3. Tokenize\n",
        "df['tokens'] = df['clean_text'].apply(word_tokenize)\n",
        "\n",
        "# 4. Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "\n",
        "# 5. Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "\n",
        "# 6. (Optional) Remove rare and frequent words\n",
        "all_words = [word for tokens in df['tokens'] for word in tokens]\n",
        "word_freq = Counter(all_words)\n",
        "\n",
        "rare_thresh = 2      # words appearing less than 2 times\n",
        "freq_thresh = 0.9    # words appearing in >90% of documents\n",
        "\n",
        "rare_words = {w for w, c in word_freq.items() if c < rare_thresh}\n",
        "total_docs = len(df)\n",
        "freq_words = {w for w, c in word_freq.items() if c/total_docs > freq_thresh}\n",
        "\n",
        "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in rare_words and word not in freq_words])\n",
        "\n",
        "# 7. (Optional) Reconstruct tokens back into cleaned sentence\n",
        "df['final_text'] = df['tokens'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# Check sample\n",
        "print(df[['tweet_text','final_text','cyberbullying_type']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kLYMqN7dcgu",
        "outputId": "b54df848-3c0e-4892-80bd-ebbf2f072c4c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          tweet_text  \\\n",
            "0  In other words #katandandre, your food was cra...   \n",
            "1  Why is #aussietv so white? #MKR #theblock #ImA...   \n",
            "2  @XochitlSuckkks a classy whore? Or more red ve...   \n",
            "3  @Jason_Gio meh. :P  thanks for the heads up, b...   \n",
            "4  @RudhoeEnglish This is an ISIS account pretend...   \n",
            "\n",
            "                                          final_text cyberbullying_type  \n",
            "0                          word katandandre food mkr  not_cyberbullying  \n",
            "1  white mkr theblock imacelebrityau today sunris...  not_cyberbullying  \n",
            "2                    classy whore red velvet cupcake  not_cyberbullying  \n",
            "3  jasongio meh p thanks head concerned another a...  not_cyberbullying  \n",
            "4  rudhoeenglish isi account pretending kurdish a...  not_cyberbullying  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "3. Feature Extraction & Selection\n",
        "Represent text as numerical features using:\n",
        "TF-IDF vectors (word-level, n-grams, or character-level)\n",
        "Word embeddings (Word2Vec, GloVe, FastText)\n",
        "Transformer-based embeddings (BERT, DistilBERT)\n",
        "Select relevant features (e.g., Chi-Square test, mutual information) to improve efficiency.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "meXKDeged9V3",
        "outputId": "255c76cd-ede6-4091-8a0e-87dab888775b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n3. Feature Extraction & Selection\\nRepresent text as numerical features using:\\nTF-IDF vectors (word-level, n-grams, or character-level)\\nWord embeddings (Word2Vec, GloVe, FastText)\\nTransformer-based embeddings (BERT, DistilBERT)\\nSelect relevant features (e.g., Chi-Square test, mutual information) to improve efficiency.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Word-level TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))  # unigrams + bigrams\n",
        "X_tfidf = tfidf.fit_transform(df['final_text'])\n",
        "y = df['cyberbullying_type']\n",
        "\n",
        "print(\"TF-IDF shape:\", X_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O2Alme9eBLa",
        "outputId": "c942d923-3c02-4cc9-e019-1f59043e478b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF shape: (47656, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Selection\n",
        "# Chi-Square Test\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "chi2_selector = SelectKBest(chi2, k=2000)  # keep top 2000 features\n",
        "X_chi2 = chi2_selector.fit_transform(X_tfidf, y)\n",
        "\n",
        "print(\"Chi-Square reduced shape:\", X_chi2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e6vXUGcewER",
        "outputId": "c3a7c795-3906-40f3-a541-cc171af91ef5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-Square reduced shape: (47656, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "4. Model Selection\n",
        "Research suitable algorithms for text classification:\n",
        "Logistic Regression\n",
        "Naive Bayes (MultinomialNB)\n",
        "Support Vector Machine (SVM)\n",
        "Random Forest / Gradient Boosting\n",
        "Deep learning models (LSTM, BiLSTM, Transformer-based models)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gfsA7-Tcf5nw",
        "outputId": "ac3604b3-c637-4fe9-f31e-88bc2e16f743"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n4. Model Selection\\nResearch suitable algorithms for text classification:\\nLogistic Regression\\nNaive Bayes (MultinomialNB)\\nSupport Vector Machine (SVM)\\nRandom Forest / Gradient Boosting\\nDeep learning models (LSTM, BiLSTM, Transformer-based models)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# IMPORTS\n",
        "# ===============================\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# ===============================\n",
        "# LOAD DATA\n",
        "# ===============================\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ramizcihe/week4-cihe240058/refs/heads/main/cyberbullying_tweets.csv\")  # Replace with your CSV path\n",
        "\n",
        "# ===============================\n",
        "# QUICK CHECK\n",
        "# ===============================\n",
        "print(\"Columns:\", df.columns)\n",
        "print(\"First 5 rows:\\n\", df.head())\n",
        "print(\"Label distribution:\\n\", df['cyberbullying_type'].value_counts())\n",
        "\n",
        "# ===============================\n",
        "# BASIC CLEANING\n",
        "# ===============================\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Remove rows with empty tweets\n",
        "df = df[df['tweet_text'].str.strip() != \"\"]\n",
        "\n",
        "# ===============================\n",
        "# FEATURE & LABEL\n",
        "# ===============================\n",
        "X = df['tweet_text']                  # Features\n",
        "y = df['cyberbullying_type']          # Target labels\n",
        "\n",
        "# ===============================\n",
        "# LABEL ENCODING\n",
        "# ===============================\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "print(\"Classes:\", label_encoder.classes_)\n",
        "\n",
        "# ===============================\n",
        "# TRAIN-TEST SPLIT\n",
        "# ===============================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# TEXT VECTORIZATION\n",
        "# ===============================\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=5000,      # limit to top 5000 words\n",
        "    stop_words='english'\n",
        ")\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# ===============================\n",
        "# READY FOR MODELING\n",
        "# ===============================\n",
        "print(\"Shape of X_train:\", X_train_tfidf.shape)\n",
        "print(\"Shape of X_test:\", X_test_tfidf.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPx_b2Ldf0ju",
        "outputId": "887cc050-7d02-4937-ba47-4131803f96de"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: Index(['tweet_text', 'cyberbullying_type'], dtype='object')\n",
            "First 5 rows:\n",
            "                                           tweet_text cyberbullying_type\n",
            "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
            "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
            "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
            "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
            "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying\n",
            "Label distribution:\n",
            " cyberbullying_type\n",
            "religion               7998\n",
            "age                    7992\n",
            "gender                 7973\n",
            "ethnicity              7961\n",
            "not_cyberbullying      7945\n",
            "other_cyberbullying    7823\n",
            "Name: count, dtype: int64\n",
            "Classes: ['age' 'ethnicity' 'gender' 'not_cyberbullying' 'other_cyberbullying'\n",
            " 'religion']\n",
            "Shape of X_train: (38124, 5000)\n",
            "Shape of X_test: (9532, 5000)\n",
            "Shape of y_train: (38124,)\n",
            "Shape of y_test: (9532,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# IMPORTS\n",
        "# ===============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ===============================\n",
        "# LOAD DATA\n",
        "# ===============================\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ramizcihe/week4-cihe240058/refs/heads/main/cyberbullying_tweets.csv\")  # Replace with your CSV path\n",
        "\n",
        "# ===============================\n",
        "# BASIC CLEANING\n",
        "# ===============================\n",
        "df = df.drop_duplicates()\n",
        "df = df[df['tweet_text'].str.strip() != \"\"]\n",
        "\n",
        "# ===============================\n",
        "# LABEL ENCODING\n",
        "# ===============================\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['cyberbullying_type'])\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y_categorical = to_categorical(y)  # For multi-class classification\n",
        "\n",
        "# ===============================\n",
        "# TRAIN-TEST SPLIT\n",
        "# ===============================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['tweet_text'], y_categorical,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# TOKENIZATION & PADDING\n",
        "# ===============================\n",
        "max_words = 10000     # Max number of words to keep in tokenizer\n",
        "max_len = 100         # Max length of sequences (padded)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# ===============================\n",
        "# LSTM / BiLSTM MODEL\n",
        "# ===============================\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# ===============================\n",
        "# TRAINING\n",
        "# ===============================\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# EVALUATION\n",
        "# ===============================\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "lcmXb9nIg3yG",
        "outputId": "b23ba376-9d06-4afc-83c8-a87b6160de8f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 272ms/step - accuracy: 0.6139 - loss: 0.9353 - val_accuracy: 0.8041 - val_loss: 0.4375\n",
            "Epoch 2/5\n",
            "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 262ms/step - accuracy: 0.8463 - loss: 0.3626 - val_accuracy: 0.8416 - val_loss: 0.4046\n",
            "Epoch 3/5\n",
            "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 306ms/step - accuracy: 0.8891 - loss: 0.2794 - val_accuracy: 0.8408 - val_loss: 0.4174\n",
            "Epoch 4/5\n",
            "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 321ms/step - accuracy: 0.9133 - loss: 0.2267 - val_accuracy: 0.8167 - val_loss: 0.4607\n",
            "Epoch 5/5\n",
            "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 275ms/step - accuracy: 0.9217 - loss: 0.1974 - val_accuracy: 0.8280 - val_loss: 0.5089\n",
            "\u001b[1m298/298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.8243 - loss: 0.5157\n",
            "Test Accuracy: 82.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqYWtAUSlcIy",
        "outputId": "8f6c45e5-fa7c-4b8f-ea78-c5398868a875"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['tweet_text', 'cyberbullying_type'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "5. Dataset Splitting\n",
        "Split into training (70%), validation (15%), and test (15%) sets.\n",
        "Use stratified splitting to maintain class proportion.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "e-yrspp0gdMc",
        "outputId": "403bbf50-9da3-452d-dbb5-847897e3059a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n5. Dataset Splitting\\nSplit into training (70%), validation (15%), and test (15%) sets.\\nUse stratified splitting to maintain class proportion.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q12W6mWCgi-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}